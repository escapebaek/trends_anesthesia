import json
import os
import re
import google.generativeai as genai
from dotenv import load_dotenv
from datetime import datetime

# .env ÌååÏùºÏóêÏÑú ÌôòÍ≤ΩÎ≥ÄÏàò Î°úÎìú
load_dotenv()

# ÌôòÍ≤ΩÎ≥ÄÏàòÏóêÏÑú API ÌÇ§ Í∞ÄÏ†∏Ïò§Í∏∞
API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    raise ValueError("""
    ‚ùå GEMINI_API_KEYÍ∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.
    
    Îã§Ïùå Ï§ë ÌïòÎÇòÏùò Î∞©Î≤ïÏúºÎ°ú ÏÑ§Ï†ïÌïòÏÑ∏Ïöî:
    
    1. .env ÌååÏùº ÏÉùÏÑ± (Í∂åÏû•):
       GEMINI_API_KEY=your_api_key_here
    
    2. ÏãúÏä§ÌÖú ÌôòÍ≤ΩÎ≥ÄÏàò ÏÑ§Ï†ï:
       export GEMINI_API_KEY=your_api_key_here  # Linux/Mac
       set GEMINI_API_KEY=your_api_key_here     # Windows
    
    3. Python Ïã§Ìñâ Ïãú ÌôòÍ≤ΩÎ≥ÄÏàò ÏÑ§Ï†ï:
       GEMINI_API_KEY=your_api_key python analyze_with_gemini.py
    """)

genai.configure(api_key=API_KEY)

# 1. Îç∞Ïù¥ÌÑ∞ Î°úÎìú
try:
    with open("abstracts_for_gemini.json", "r", encoding="utf-8") as f:
        abstracts = json.load(f)
except FileNotFoundError:
    print("‚ùå abstracts_for_gemini.json ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
    print("üí° Î®ºÏ†Ä fetch_pubmed.pyÏôÄ prepare_for_gemini.pyÎ•º Ïã§ÌñâÌïòÏÑ∏Ïöî.")
    exit(1)

# ÎÇ†Ïßú Ï†ïÎ≥¥ Î∂ÑÏÑù
papers_with_dates = [paper for paper in abstracts if paper.get("publication_date")]
if papers_with_dates:
    dates = [datetime.strptime(paper["publication_date"], "%Y-%m-%d") for paper in papers_with_dates]
    newest_date = max(dates)
    oldest_date = min(dates)
    
    print(f"üìÖ ÎÖºÎ¨∏ Î∞úÌñâ ÎÇ†Ïßú Î≤îÏúÑ:")
    print(f"   - ÏµúÏã†: {newest_date.strftime('%YÎÖÑ %mÏõî %dÏùº')}")
    print(f"   - ÏµúÏò§ÎûòÎêú: {oldest_date.strftime('%YÎÖÑ %mÏõî %dÏùº')}")
    print(f"   - ÎÇ†Ïßú Ï†ïÎ≥¥Í∞Ä ÏûàÎäî ÎÖºÎ¨∏: {len(papers_with_dates)}Í∞ú")

# 2. ÎßàÏ∑®Ìïô Î∂ÑÎ•ò Ïπ¥ÌÖåÍ≥†Î¶¨ Ï†ïÏùò
anesthesia_categories = [
    "ÎßàÏ∑®Ï†Ñ Í¥ÄÎ¶¨ (Pre-op Evaluation)",
    "ÎßàÏ∑® ÏïΩÎ¶¨(Pharmacology of Anesthetics)",
    "Î≤ïÏùòÌïô Î∞è Ïú§Î¶¨(Forensic and Ethical Considerations in Anesthesia)",
    "ÎßàÏ∑®Ïû•ÎπÑ Î∞è Í∞êÏãú(Anesthesia Equipment and Monitoring)",
    "Í∏∞ÎèÑÍ¥ÄÎ¶¨(Airway Management)",
    "Ìù°ÏûÖÎßàÏ∑®(Inhalation Anesthesia)",
    "Ï†ïÎß•ÎßàÏ∑®(Intravenous Anesthesia)",
    "Ïã†Í≤ΩÍ∑ºÏ∞®Îã®(Neuromuscular Blockade)",
    "Î∂ÄÏúÑÎßàÏ∑®(Regional Anesthesia)",
    "ÏàòÏï° Î∞è ÏàòÌòà(Fluid Management and Transfusion)",
    "ÏÇ∞Í≥ºÎßàÏ∑®(Obstetric Anesthesia)",
    "ÏÜåÏïÑÎßàÏ∑®(Pediatric Anesthesia)",
    "Ïã¨Ïû•ÎßàÏ∑®(Cardiac Anesthesia)",
    "ÌèêÎßàÏ∑®(Thoracic Anesthesia)",
    "ÎáåÏã†Í≤ΩÎßàÏ∑®(Neuroanesthesia)",
    "ÏàòÏà†Ïû• Î∞ñ ÏßÑÏ†ï Î∞è ÎßàÏ∑®(Sedation and Anesthesia Outside the Operating Room)",
    "ÏàòÏà† ÌõÑ ÌÜµÏ¶ùÍ¥ÄÎ¶¨(Postoperative Pain Management)",
    "ÌÜµÏ¶ùÍ¥ÄÎ¶¨(Pain Management)",
    "ÎÖ∏Ïù∏ÎßàÏ∑®(Geriatric Anesthesia)",
    "Ïô∏ÎûòÎßàÏ∑®(Outpatient Anesthesia)",
    "Ïã¨ÌèêÏÜåÏÉùÏà†(CPR)",
    "Ï§ëÌôòÏûêÍ¥ÄÎ¶¨(Critical Care Management)",
    "Ïû•Í∏∞Ïù¥Ïãù(Transplantation Anesthesia)"
]

# 3. ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ± (ÏÉàÎ°úÏö¥ Î∂ÑÎ•ò Î∞©Ïãù)
date_context = ""
if papers_with_dates:
    date_context = f"""
    
    IMPORTANT DATE CONTEXT:
    - This analysis covers papers published from {oldest_date.strftime('%Y-%m-%d')} to {newest_date.strftime('%Y-%m-%d')}
    - Total papers with date information: {len(papers_with_dates)}
    - This represents the most current research trends in anesthesia for 2025
    """

categories_text = "\n".join(f"- {cat}" for cat in anesthesia_categories)

prompt = f"""You are an expert anesthesiologist and research analyst. Analyze the following anesthesia-related paper abstracts and classify them into specific categories.

{date_context}

CLASSIFICATION CATEGORIES:
{categories_text}

TASK:
1. For each abstract, determine the most appropriate category from the list above
2. Within each category, identify specific subtopics (e.g., "Kidney transplantation", "Liver transplantation" under "Ïû•Í∏∞Ïù¥Ïãù")
3. Provide a concise summary of each abstract (2-3 sentences)
4. Return the results in the following JSON structure:

{{
  "ÎßàÏ∑®Ï†Ñ Í¥ÄÎ¶¨ (Pre-op Evaluation)": {{
    "Preoperative Risk Assessment": [
      {{
        "pmid": "12345678",
        "title": "Risk factors for postoperative complications",
        "author": "Kim HS, Lee JW",
        "journal": "Anesthesiology",
        "link": "https://pubmed.ncbi.nlm.nih.gov/12345678/",
        "issue_date": "2025-07",
        "abstract_summary": "This study investigated preoperative risk factors..."
      }}
    ]
  }},
  "ÎßàÏ∑® ÏïΩÎ¶¨(Pharmacology of Anesthetics)": {{
    "Propofol Pharmacokinetics": [
      {{
        "pmid": "...",
        "title": "...",
        "author": "...",
        "journal": "...",
        "link": "...",
        "issue_date": "...",
        "abstract_summary": "..."
      }}
    ]
  }}
}}

INSTRUCTIONS:
- Create specific subtopic names based on the content (avoid generic terms)
- Each subtopic should contain an array of papers
- Abstract summaries should be concise but informative (2-3 sentences)
- Use the exact PMID, title, author, journal, and link from the provided data
- Format issue_date as "YYYY-MM" if available
- If a paper doesn't clearly fit any category, classify it as the closest match
- Do not include markdown, code fences, or explanations - return only valid JSON

ABSTRACTS TO ANALYZE:
"""

# ÎÖºÎ¨∏ Îç∞Ïù¥ÌÑ∞Î•º ÌîÑÎ°¨ÌîÑÌä∏Ïóê Ï∂îÍ∞Ä
for i, item in enumerate(abstracts):
    prompt += f"\n{i+1}. PMID: {item.get('pmid', 'N/A')} | Journal: {item['journal']} | Date: {item.get('publication_date', 'Unknown')} | Link: {item['link']}\n"
    prompt += f"Title: {item['title']}\n"
    prompt += f"Authors: {item.get('authors', 'N/A')}\n"
    prompt += f"Abstract: {item['abstract']}\n"

# 4. Î™®Îç∏ Ìò∏Ï∂ú
try:
    print("ü§ñ Gemini API Ìò∏Ï∂ú Ï§ë...")
    print(f"üìä Î∂ÑÏÑùÌï† ÎÖºÎ¨∏ Ïàò: {len(abstracts)}Í∞ú")
    model = genai.GenerativeModel("gemini-2.5-pro")
    response = model.generate_content(prompt)
    print("‚úÖ API Ìò∏Ï∂ú ÏÑ±Í≥µ")
except Exception as e:
    print(f"‚ùå Gemini API Ìò∏Ï∂ú Ïã§Ìå®: {e}")
    print("üí° API ÌÇ§Í∞Ä Ïò¨Î∞îÎ•∏ÏßÄ, Ìï†ÎãπÎüâÏù¥ ÎÇ®ÏïÑÏûàÎäîÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî.")
    exit(1)

# 5. JSON Ï∂îÏ∂ú Î∞è ÌååÏã±
raw_text = response.text.strip()
print("üîç JSON Ï∂îÏ∂ú Ï§ë...")

# JSON Î∏îÎ°ù Ï∞æÍ∏∞
json_match = re.search(r'\{.*\}', raw_text, re.DOTALL)
if json_match:
    json_str = json_match.group(0)
else:
    # Î∞±Ìã±Ïù¥ÎÇò Îã§Î•∏ ÎßàÌÅ¨Îã§Ïö¥ ÏöîÏÜå Ï†úÍ±∞
    json_str = re.sub(r'```json\s*', '', raw_text)
    json_str = re.sub(r'```\s*$', '', json_str)
    json_str = json_str.strip()

# 6. JSON ÌååÏã±
try:
    classified_data = json.loads(json_str)
    print(f"‚úÖ JSON ÌååÏã± ÏÑ±Í≥µ")
    
    # Î∂ÑÎ•ò Í≤∞Í≥º ÌÜµÍ≥Ñ
    total_papers = 0
    category_counts = {}
    
    for category, subtopics in classified_data.items():
        category_count = 0
        for subtopic, papers in subtopics.items():
            category_count += len(papers)
        category_counts[category] = category_count
        total_papers += category_count
    
    print(f"üìä Î∂ÑÎ•ò Í≤∞Í≥º:")
    print(f"   - Ï¥ù Î∂ÑÎ•òÎêú ÎÖºÎ¨∏: {total_papers}Í∞ú")
    print(f"   - ÌôúÏÑ± Ïπ¥ÌÖåÍ≥†Î¶¨: {len([c for c in category_counts.values() if c > 0])}Í∞ú")
    
    # ÏÉÅÏúÑ 5Í∞ú Ïπ¥ÌÖåÍ≥†Î¶¨ Ï∂úÎ†•
    sorted_categories = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)
    print(f"   - ÏÉÅÏúÑ Ïπ¥ÌÖåÍ≥†Î¶¨:")
    for cat, count in sorted_categories[:5]:
        if count > 0:
            print(f"     ‚Ä¢ {cat}: {count}Í∞ú")

except json.JSONDecodeError as e:
    print("‚ùå JSON ÌååÏã± Ïã§Ìå®:", e)
    print("Raw Ï∂úÎ†• (Ï≤òÏùå 1000Ïûê):\n", raw_text[:1000])
    print("\nÎßàÏßÄÎßâ 1000Ïûê:\n", raw_text[-1000:])
    
    # Îπà Íµ¨Ï°∞Î°ú Ï¥àÍ∏∞Ìôî
    classified_data = {}
    for category in anesthesia_categories:
        classified_data[category] = {}

# 7. Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ÏôÄ Ìï®Íªò Ï†ÄÏû•
output_data = {
    "metadata": {
        "analysis_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "total_papers_analyzed": len(abstracts),
        "total_papers_classified": sum(
            len(papers) for subtopics in classified_data.values() 
            for papers in subtopics.values()
        ) if classified_data else 0,
        "papers_with_dates": len(papers_with_dates),
        "date_range": {
            "oldest": oldest_date.strftime("%Y-%m-%d") if papers_with_dates else None,
            "newest": newest_date.strftime("%Y-%m-%d") if papers_with_dates else None,
            "oldest_formatted": oldest_date.strftime("%YÎÖÑ %mÏõî %dÏùº") if papers_with_dates else None,
            "newest_formatted": newest_date.strftime("%YÎÖÑ %mÏõî %dÏùº") if papers_with_dates else None
        },
        "categories_used": len([cat for cat, subtopics in classified_data.items() 
                              if any(len(papers) > 0 for papers in subtopics.values())]) if classified_data else 0,
        "category_distribution": {
            category: sum(len(papers) for papers in subtopics.values())
            for category, subtopics in classified_data.items()
        } if classified_data else {}
    },
    "classified_abstracts": classified_data
}

# 8. ÌååÏùº Ï†ÄÏû•
# Í∏∞Î≥∏ Î∂ÑÎ•ò Í≤∞Í≥º
output_file = "anesthesia_classified_abstracts.json"
with open(output_file, "w", encoding="utf-8") as f:
    json.dump(classified_data, f, ensure_ascii=False, indent=2)

# Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ìè¨Ìï® Î≤ÑÏ†Ñ
output_file_with_meta = "anesthesia_classified_with_metadata.json"
with open(output_file_with_meta, "w", encoding="utf-8") as f:
    json.dump(output_data, f, ensure_ascii=False, indent=2)

print(f"\n‚úÖ Î∂ÑÎ•ò Í≤∞Í≥º Ï†ÄÏû• ÏôÑÎ£å:")
print(f"   ‚Üí {output_file} (Î∂ÑÎ•ò Í≤∞Í≥ºÎßå)")
print(f"   ‚Üí {output_file_with_meta} (Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ìè¨Ìï®)")

if classified_data:
    print(f"üìà Î∂ÑÎ•ò ÌÜµÍ≥Ñ:")
    print(f"   - Ï¥ù Ïπ¥ÌÖåÍ≥†Î¶¨: {len(anesthesia_categories)}Í∞ú")
    print(f"   - ÏÇ¨Ïö©Îêú Ïπ¥ÌÖåÍ≥†Î¶¨: {len([cat for cat, subtopics in classified_data.items() if any(len(papers) > 0 for papers in subtopics.values())])}Í∞ú")
    print(f"   - Ï¥ù ÏÑ∏Î∂ÄÏ£ºÏ†ú: {sum(len(subtopics) for subtopics in classified_data.values())}Í∞ú")

if papers_with_dates:
    print(f"üìÖ Î∂ÑÏÑù Í∏∞Í∞Ñ: {oldest_date.strftime('%YÎÖÑ %mÏõî %dÏùº')} ~ {newest_date.strftime('%YÎÖÑ %mÏõî %dÏùº')}")

print(f"üí° Îã§Ïùå Îã®Í≥Ñ: python visualize_classified_trends.py")