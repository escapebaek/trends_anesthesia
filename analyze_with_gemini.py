import json
import os
import re
import google.generativeai as genai
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    raise ValueError("""
    âŒ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
    
    ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ë°©ë²•ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”:
    
    1. .env íŒŒì¼ ìƒì„± (ê¶Œì¥):
       GEMINI_API_KEY=your_api_key_here
    
    2. ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
       export GEMINI_API_KEY=your_api_key_here  # Linux/Mac
       set GEMINI_API_KEY=your_api_key_here     # Windows
    
    3. Python ì‹¤í–‰ ì‹œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
       GEMINI_API_KEY=your_api_key python analyze_with_gemini.py
    """)

genai.configure(api_key=API_KEY)

# 1. ë°ì´í„° ë¡œë“œ
try:
    with open("abstracts_for_gemini.json", "r", encoding="utf-8") as f:
        abstracts = json.load(f)
except FileNotFoundError:
    print("âŒ abstracts_for_gemini.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ğŸ’¡ ë¨¼ì € fetch_pubmed.pyì™€ prepare_for_gemini.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    exit(1)

# 2. í”„ë¡¬í”„íŠ¸ (ì„¸ë¶€ ë…¼ë¬¸ ë§í¬ í¬í•¨, ì„¸ë¶„í™”ëœ í‚¤ì›Œë“œ ê·¸ë£¹í™”)
prompt = (
    "You are an expert research assistant. Analyze the following anesthesia-related paper abstracts grouped by journal.\n\n"
    "Task:\n"
    "1. For each journal, identify 12-15 research topic clusters with specific focus areas.\n"
    "2. Do NOT create overly broad clusters (e.g., avoid 'Regional Anesthesia'); instead, split them into detailed subtopics (e.g., 'Adductor Canal Block', 'Erector Spinae Plane Block').\n"
    "3. For each cluster, provide:\n"
    "   - topic (string): a specific representative name (avoid generic terms)\n"
    "   - count (integer): number of abstracts mentioning any keyword in this cluster\n"
    "   - related_keywords (array): 3-5 specific keywords contained in the cluster\n"
    "   - article_links (array): PubMed links of 3-5 representative articles related to this cluster\n"
    "   - description (string): concise summary (5-10 words)\n"
    "4. Use only the provided article links when filling the 'article_links' field.\n"
    "5. Avoid generic words like 'patients', 'surgery', 'pain', 'human'.\n"
    "6. Include drug names, specific techniques, biomarkers, and precise clinical outcomes where applicable.\n"
    "7. Return strictly a JSON object where each key is a journal name, and its value is an array of topic clusters.\n"
    "8. Do not include markdown, code fences, or explanations.\n\n"
    "Example cluster entry: \n"
    "{ \"topic\": \"Adductor Canal Block\", \"count\": 7, \"related_keywords\": [\"ACB\", \"nerve block\", \"postoperative analgesia\"], \"article_links\": [\"https://pubmed.ncbi.nlm.nih.gov/12345678/\", \"https://pubmed.ncbi.nlm.nih.gov/23456789/\"], \"description\": \"Specific nerve block for knee surgery pain\" }\n\n"
    "Abstracts (with journal and article link):\n" +
    "\n\n".join(f"{i+1}. Journal: {item['journal']} | Link: {item['link']} | Abstract: {item['abstract']}" for i, item in enumerate(abstracts))
)

# 3. ëª¨ë¸ í˜¸ì¶œ
try:
    print("ğŸ¤– Gemini API í˜¸ì¶œ ì¤‘...")
    model = genai.GenerativeModel("gemini-2.5-pro")
    response = model.generate_content(prompt)
    print("âœ… API í˜¸ì¶œ ì„±ê³µ")
except Exception as e:
    print(f"âŒ Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
    print("ğŸ’¡ API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€, í• ë‹¹ëŸ‰ì´ ë‚¨ì•„ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    exit(1)

# 4. JSON ì¶”ì¶œ
raw_text = response.text.strip()
match = re.search(r"\{.*\}", raw_text, re.S)
json_str = match.group(0) if match else raw_text

# 5. JSON íŒŒì‹±
try:
    trends_by_journal = json.loads(json_str)
    print(f"âœ… JSON íŒŒì‹± ì„±ê³µ - {len(trends_by_journal)}ê°œ ì €ë„ ë°ì´í„°")
except json.JSONDecodeError as e:
    print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
    print("Raw ì¶œë ¥ (ì²˜ìŒ 500ì):\n", raw_text[:500])
    trends_by_journal = {}

# 6. ì €ì¥
output_file = "anesthesia_trends_by_journal_with_article_links.json"
with open(output_file, "w", encoding="utf-8") as f:
    json.dump(trends_by_journal, f, ensure_ascii=False, indent=2)

print(f"âœ… ì €ì¥ ì™„ë£Œ â†’ {output_file} (ì„¸ë¶€ í‚¤ì›Œë“œë³„ ë…¼ë¬¸ ë§í¬ í¬í•¨)")
print(f"ğŸ“Š ë¶„ì„ëœ ì´ í† í”½ ìˆ˜: {sum(len(topics) for topics in trends_by_journal.values())}")