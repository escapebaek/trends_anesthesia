import json
import os
import re
import google.generativeai as genai
from dotenv import load_dotenv
from datetime import datetime

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    raise ValueError("""
    âŒ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
    
    ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ë°©ë²•ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”:
    
    1. .env íŒŒì¼ ìƒì„± (ê¶Œì¥):
       GEMINI_API_KEY=your_api_key_here
    
    2. ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
       export GEMINI_API_KEY=your_api_key_here  # Linux/Mac
       set GEMINI_API_KEY=your_api_key_here     # Windows
    
    3. Python ì‹¤í–‰ ì‹œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
       GEMINI_API_KEY=your_api_key python analyze_with_gemini.py
    """)

genai.configure(api_key=API_KEY)

# 1. ë°ì´í„° ë¡œë“œ
try:
    with open("abstracts_for_gemini.json", "r", encoding="utf-8") as f:
        abstracts = json.load(f)
except FileNotFoundError:
    print("âŒ abstracts_for_gemini.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ğŸ’¡ ë¨¼ì € fetch_pubmed.pyì™€ prepare_for_gemini.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    exit(1)

# ë‚ ì§œ ì •ë³´ ë¶„ì„
papers_with_dates = [paper for paper in abstracts if paper.get("publication_date")]
if papers_with_dates:
    dates = [datetime.strptime(paper["publication_date"], "%Y-%m-%d") for paper in papers_with_dates]
    newest_date = max(dates)
    oldest_date = min(dates)
    
    print(f"ğŸ“… ë…¼ë¬¸ ë°œí–‰ ë‚ ì§œ ë²”ìœ„:")
    print(f"   - ìµœì‹ : {newest_date.strftime('%Yë…„ %mì›” %dì¼')}")
    print(f"   - ìµœì˜¤ë˜ëœ: {oldest_date.strftime('%Yë…„ %mì›” %dì¼')}")
    print(f"   - ë‚ ì§œ ì •ë³´ê°€ ìˆëŠ” ë…¼ë¬¸: {len(papers_with_dates)}ê°œ")

# 2. ë§ˆì·¨í•™ ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ ì •ì˜
anesthesia_categories = [
    "ë§ˆì·¨ì „ ê´€ë¦¬ (Pre-op Evaluation)",
    "ë§ˆì·¨ ì•½ë¦¬(Pharmacology of Anesthetics)",
    "ë²•ì˜í•™ ë° ìœ¤ë¦¬(Forensic and Ethical Considerations in Anesthesia)",
    "ë§ˆì·¨ì¥ë¹„ ë° ê°ì‹œ(Anesthesia Equipment and Monitoring)",
    "ê¸°ë„ê´€ë¦¬(Airway Management)",
    "í¡ì…ë§ˆì·¨(Inhalation Anesthesia)",
    "ì •ë§¥ë§ˆì·¨(Intravenous Anesthesia)",
    "ì‹ ê²½ê·¼ì°¨ë‹¨(Neuromuscular Blockade)",
    "ë¶€ìœ„ë§ˆì·¨(Regional Anesthesia)",
    "ìˆ˜ì•¡ ë° ìˆ˜í˜ˆ(Fluid Management and Transfusion)",
    "ì‚°ê³¼ë§ˆì·¨(Obstetric Anesthesia)",
    "ì†Œì•„ë§ˆì·¨(Pediatric Anesthesia)",
    "ì‹¬ì¥ë§ˆì·¨(Cardiac Anesthesia)",
    "íë§ˆì·¨(Thoracic Anesthesia)",
    "ë‡Œì‹ ê²½ë§ˆì·¨(Neuroanesthesia)",
    "ìˆ˜ìˆ ì¥ ë°– ì§„ì • ë° ë§ˆì·¨(Sedation and Anesthesia Outside the Operating Room)",
    "ìˆ˜ìˆ  í›„ í†µì¦ê´€ë¦¬(Postoperative Pain Management)",
    "í†µì¦ê´€ë¦¬(Pain Management)",
    "ë…¸ì¸ë§ˆì·¨(Geriatric Anesthesia)",
    "ì™¸ë˜ë§ˆì·¨(Outpatient Anesthesia)",
    "ì‹¬íì†Œìƒìˆ (CPR)",
    "ì¤‘í™˜ìê´€ë¦¬(Critical Care Management)",
    "ì¥ê¸°ì´ì‹(Transplantation Anesthesia)"
]

# 3. í”„ë¡¬í”„íŠ¸ ìƒì„± (ìƒˆë¡œìš´ ë¶„ë¥˜ ë°©ì‹)
date_context = ""
if papers_with_dates:
    date_context = f"""
    
    IMPORTANT DATE CONTEXT:
    - This analysis covers papers published from {oldest_date.strftime('%Y-%m-%d')} to {newest_date.strftime('%Y-%m-%d')}
    - Total papers with date information: {len(papers_with_dates)}
    - This represents the most current research trends in anesthesia for 2025
    """

categories_text = "\n".join(f"- {cat}" for cat in anesthesia_categories)

prompt = f"""You are an expert anesthesiologist and research analyst. Analyze the following anesthesia-related paper abstracts and classify them into specific categories.

{date_context}

CLASSIFICATION CATEGORIES:
{categories_text}

TASK:
1. For each abstract, determine the most appropriate category from the list above
2. Within each category, identify specific subtopics (e.g., "Kidney transplantation", "Liver transplantation" under "ì¥ê¸°ì´ì‹")
3. Provide a concise summary of each abstract (2-3 sentences)
4. Return the results in the following JSON structure:

{{
  "ë§ˆì·¨ì „ ê´€ë¦¬ (Pre-op Evaluation)": {{
    "Preoperative Risk Assessment": [
      {{
        "pmid": "12345678",
        "title": "Risk factors for postoperative complications",
        "author": "Kim HS, Lee JW",
        "journal": "Anesthesiology",
        "link": "https://pubmed.ncbi.nlm.nih.gov/12345678/",
        "issue_date": "2025-07",
        "abstract_summary": "This study investigated preoperative risk factors..."
      }}
    ]
  }},
  "ë§ˆì·¨ ì•½ë¦¬(Pharmacology of Anesthetics)": {{
    "Propofol Pharmacokinetics": [
      {{
        "pmid": "...",
        "title": "...",
        "author": "...",
        "journal": "...",
        "link": "...",
        "issue_date": "...",
        "abstract_summary": "..."
      }}
    ]
  }}
}}

INSTRUCTIONS:
- Create specific subtopic names based on the content (avoid generic terms)
- Each subtopic should contain an array of papers
- Abstract summaries should be concise but informative (2-3 sentences)
- Use the exact PMID, title, author, journal, and link from the provided data
- Format issue_date as "YYYY-MM" if available
- If a paper doesn't clearly fit any category, classify it as the closest match
- Do not include markdown, code fences, or explanations - return only valid JSON

ABSTRACTS TO ANALYZE:
"""

# ë…¼ë¬¸ ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
for i, item in enumerate(abstracts):
    prompt += f"\n{i+1}. PMID: {item.get('pmid', 'N/A')} | Journal: {item['journal']} | Date: {item.get('publication_date', 'Unknown')} | Link: {item['link']}\n"
    prompt += f"Title: {item['title']}\n"
    prompt += f"Authors: {item.get('authors', 'N/A')}\n"
    prompt += f"Abstract: {item['abstract']}\n"

# 4. ëª¨ë¸ í˜¸ì¶œ
try:
    print("ğŸ¤– Gemini API í˜¸ì¶œ ì¤‘...")
    print(f"ğŸ“Š ë¶„ì„í•  ë…¼ë¬¸ ìˆ˜: {len(abstracts)}ê°œ")
    model = genai.GenerativeModel("gemini-2.5-pro")
    response = model.generate_content(prompt)
    print("âœ… API í˜¸ì¶œ ì„±ê³µ")
except Exception as e:
    print(f"âŒ Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
    print("ğŸ’¡ API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€, í• ë‹¹ëŸ‰ì´ ë‚¨ì•„ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    exit(1)

# 5. JSON ì¶”ì¶œ ë° íŒŒì‹±
raw_text = response.text.strip()
print("ğŸ” JSON ì¶”ì¶œ ì¤‘...")

# JSON ë¸”ë¡ ì°¾ê¸°
json_match = re.search(r'\{.*\}', raw_text, re.DOTALL)
if json_match:
    json_str = json_match.group(0)
else:
    # ë°±í‹±ì´ë‚˜ ë‹¤ë¥¸ ë§ˆí¬ë‹¤ìš´ ìš”ì†Œ ì œê±°
    json_str = re.sub(r'```json\s*', '', raw_text)
    json_str = re.sub(r'```\s*$', '', json_str)
    json_str = json_str.strip()

# 6. JSON íŒŒì‹±
try:
    classified_data = json.loads(json_str)
    print(f"âœ… JSON íŒŒì‹± ì„±ê³µ")
    
    # ë¶„ë¥˜ ê²°ê³¼ í†µê³„
    total_papers = 0
    category_counts = {}
    
    for category, subtopics in classified_data.items():
        category_count = 0
        for subtopic, papers in subtopics.items():
            category_count += len(papers)
        category_counts[category] = category_count
        total_papers += category_count
    
    print(f"ğŸ“Š ë¶„ë¥˜ ê²°ê³¼:")
    print(f"   - ì´ ë¶„ë¥˜ëœ ë…¼ë¬¸: {total_papers}ê°œ")
    print(f"   - í™œì„± ì¹´í…Œê³ ë¦¬: {len([c for c in category_counts.values() if c > 0])}ê°œ")
    
    # ìƒìœ„ 5ê°œ ì¹´í…Œê³ ë¦¬ ì¶œë ¥
    sorted_categories = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)
    print(f"   - ìƒìœ„ ì¹´í…Œê³ ë¦¬:")
    for cat, count in sorted_categories[:5]:
        if count > 0:
            print(f"     â€¢ {cat}: {count}ê°œ")

except json.JSONDecodeError as e:
    print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
    print("Raw ì¶œë ¥ (ì²˜ìŒ 1000ì):\n", raw_text[:1000])
    print("\në§ˆì§€ë§‰ 1000ì:\n", raw_text[-1000:])
    
    # ë¹ˆ êµ¬ì¡°ë¡œ ì´ˆê¸°í™”
    classified_data = {}
    for category in anesthesia_categories:
        classified_data[category] = {}

# 7. ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
output_data = {
    "metadata": {
        "analysis_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "total_papers_analyzed": len(abstracts),
        "total_papers_classified": sum(
            len(papers) for subtopics in classified_data.values() 
            for papers in subtopics.values()
        ) if classified_data else 0,
        "papers_with_dates": len(papers_with_dates),
        "date_range": {
            "oldest": oldest_date.strftime("%Y-%m-%d") if papers_with_dates else None,
            "newest": newest_date.strftime("%Y-%m-%d") if papers_with_dates else None,
            "oldest_formatted": oldest_date.strftime("%Yë…„ %mì›” %dì¼") if papers_with_dates else None,
            "newest_formatted": newest_date.strftime("%Yë…„ %mì›” %dì¼") if papers_with_dates else None
        },
        "categories_used": len([cat for cat, subtopics in classified_data.items() 
                              if any(len(papers) > 0 for papers in subtopics.values())]) if classified_data else 0,
        "category_distribution": {
            category: sum(len(papers) for papers in subtopics.values())
            for category, subtopics in classified_data.items()
        } if classified_data else {}
    },
    "classified_abstracts": classified_data
}

# 8. íŒŒì¼ ì €ì¥
# ê¸°ë³¸ ë¶„ë¥˜ ê²°ê³¼
output_file = "anesthesia_classified_abstracts.json"
with open(output_file, "w", encoding="utf-8") as f:
    json.dump(classified_data, f, ensure_ascii=False, indent=2)

# ë©”íƒ€ë°ì´í„° í¬í•¨ ë²„ì „
output_file_with_meta = "anesthesia_classified_with_metadata.json"
with open(output_file_with_meta, "w", encoding="utf-8") as f:
    json.dump(output_data, f, ensure_ascii=False, indent=2)

print(f"\nâœ… ë¶„ë¥˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
print(f"   â†’ {output_file} (ë¶„ë¥˜ ê²°ê³¼ë§Œ)")
print(f"   â†’ {output_file_with_meta} (ë©”íƒ€ë°ì´í„° í¬í•¨)")

if classified_data:
    print(f"ğŸ“ˆ ë¶„ë¥˜ í†µê³„:")
    print(f"   - ì´ ì¹´í…Œê³ ë¦¬: {len(anesthesia_categories)}ê°œ")
    print(f"   - ì‚¬ìš©ëœ ì¹´í…Œê³ ë¦¬: {len([cat for cat, subtopics in classified_data.items() if any(len(papers) > 0 for papers in subtopics.values())])}ê°œ")
    print(f"   - ì´ ì„¸ë¶€ì£¼ì œ: {sum(len(subtopics) for subtopics in classified_data.values())}ê°œ")

if papers_with_dates:
    print(f"ğŸ“… ë¶„ì„ ê¸°ê°„: {oldest_date.strftime('%Yë…„ %mì›” %dì¼')} ~ {newest_date.strftime('%Yë…„ %mì›” %dì¼')}")

print(f"ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: python visualize_classified_trends.py")